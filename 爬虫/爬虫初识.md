
- 什么是爬虫？
    - 就是通过编写程序**模拟**浏览器上网，
    然后让其去互联网上爬取数据的自动化程序

- 爬虫的分类：
    - 通用爬虫：
        - 抓取互联网中的一整张页面数据
    - 聚焦爬虫：
        - 抓取页面中的局部数据
    - 增量式爬虫：
        - 用来**监测网站数据更新**的情况，以便爬取到网站最新更新出来的数据

- 反爬机制: 防止爬虫程序获取网站数据
    - 请求载体标识: `User-Agent`
    - ip访问频率限制
    - 数据加密
    - `robots`协议, 君子协议

- 反反爬策略: 破解反爬机制，获取被保护的数据

- 爬虫合法吗？
    - 爬取数据的行为**风险**的体现
       -  爬虫干扰了被访问网站的正常运营
       -  爬虫抓取了受到法律保护的特定类型的数据或信息。

    - 规避风险
        - **严格遵守**网站设置的`robots`协议
        - 在规避反爬虫措施的同时，需要优化自己的代码，
        **避免干扰被访问网站的正常运行**
        - 在使用、传播抓取到的信息时，应审查所抓取的内容，
        如发现属于用户的个人信息、隐私或者他人的商业秘密的，
        应及时停止并删除。

- `robots`协议：文本协议
    - 特性：防君子不防小人的文本协议

